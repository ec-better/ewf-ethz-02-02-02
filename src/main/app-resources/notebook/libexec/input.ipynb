{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Sentinel-1 feature tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This application takes a pair of Sentinel-1 products and identifies and generates the coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"quicklink\">Quick link\n",
    "\n",
    "* [Objective](#objective)\n",
    "* [Test Site](#test-site)\n",
    "* [Context](#context)\n",
    "* [Applicability](#applicability)\n",
    "* [Data](#data)\n",
    "* [Service Definition](#service)\n",
    "* [Parameter Definition](#parameter)\n",
    "* [Runtime Parameter Definition](#runtime)\n",
    "* [Workflow](#workflow)\n",
    "* [Strengths and Limitations](#strengths-limitations) \n",
    "* [License](#license)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As a data processor developer, I want to implement, and package an algorithm processing a pair of S1 SAR SLC datasets using the SNAP toolbox notebook archetype with the following processing steps:\n",
    "\n",
    "A. S1 SAR processing per image:\n",
    "\n",
    "* Application of orbit file (should wait for the orbit file a couple of days, since for coherence this is important)\n",
    "* TOPS slice assembly (if necessary)\n",
    "* TOPS split (if necessary)\n",
    "\n",
    "B. For image pair:\n",
    "\n",
    "* TOPS coregistration\n",
    "* Coherence estimation (Given set of images from same orbit,  {t1, t2, t3, ... , tn}, two temporally adjacent images would * constitute an image pair, with the first one being the master. So the pairs would be: {t1 - t2, t2 - t3, ... , tn-1 - tn}.)\n",
    "* TOPS deburst\n",
    "* Multi-looking\n",
    "* Terrain correction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOPS --> Terrain Observation by Prograssive Scans\n",
    "\n",
    "TOPS Slice assembly-->assemble subswaths back together\n",
    "\n",
    "TOPS split -->split into subswaths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'Sentinel-1 feature tracking'),\n",
    "                ('abstract', 'Sentinel-1 feature tracking'),\n",
    "                ('id', 'ewf-ethz-02-02-01')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_velocity = dict([('id', 'max_velocity'),\n",
    "                     ('value', '8'),\n",
    "                     ('title', 'Max velocity'),\n",
    "                     ('abstract', 'Max velocity (m/day)')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "polarisation = dict([('id', 'polarisation'),\n",
    "                     ('value', 'VV'),\n",
    "                     ('title', 'Polarisation'),\n",
    "                     ('abstract', 'Polarisation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = dict([('id', 'area_of_interest'),\n",
    "            ('value', 'POLYGON((-91.32114821675749 -1.141198173686936, -90.71737318778665 -1.009922494598408, -90.84942543017247 -0.5555272457029629, -91.40848642576378 -0.6637246974332075, -91.32114821675749 -1.141198173686936))'),\n",
    "            ('title', 'Area of interest in WKT'),\n",
    "            ('abstract', 'Area of interest in WKT')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = dict([('id', 'dem'),\n",
    "            ('value', 'SRTM 3Sec'),\n",
    "            ('title', 'Area of interest in WKT'),\n",
    "            ('abstract', 'Area of interest in WKT'),\n",
    "            ('options', 'SRTM 3Sec,ACE30')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = dict([(\"id\", \"resolution\"),\n",
    "                   (\"title\", \"Spatial resolution\"),\n",
    "                   (\"value\", \"40\"),\n",
    "                   (\"abstract\", \"Spatial resolution in meters (10 or 40)\"),\n",
    "                   ('options', '10,40')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utm_zone = dict([('id', 'utm_zone'),\n",
    "                 ('title', 'UTM zone'),\n",
    "                 ('abstract', 'UTM zone'),\n",
    "                 ('value', 'EPSG:32715')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = dict([('id', 'window_size'),\n",
    "                    ('title', 'window_size'),\n",
    "                    ('abstract', 'window size in pixels'),\n",
    "                    ('value', '64')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling_factor = dict([('id', 'oversampling_factor'),\n",
    "                            ('title', 'oversampling_factor'),\n",
    "                            ('abstract', 'oversampling factor'),\n",
    "                            ('value', '8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_size = dict([('id', 'pixel_size'),\n",
    "                   ('title', 'pixel_size'),\n",
    "                   ('abstract', 'pixel size in meters'),\n",
    "                   ('value', '40')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_scale_limits = dict([('id', 'color_scale_limits'),\n",
    "                           ('title', 'color_scale_limits'),\n",
    "                           ('abstract', 'color_scale_limits'),\n",
    "                           ('value', '0,10')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "These are the Sentinel-1 product identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_identifiers = ('S1A_IW_GRDH_1SDV_20190824T002619_20190824T002648_028703_033FCF_961C',\n",
    "                     'S1A_IW_GRDH_1SDV_20190929T002620_20190929T002649_029228_0351FE_D742')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "These are the Sentinel-1 catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_references = ('https://catalog.terradue.com/sentinel1/search?uid=S1A_IW_GRDH_1SDV_20190824T002619_20190824T002648_028703_033FCF_961C',\n",
    "                    'https://catalog.terradue.com/sentinel1/search?uid=S1A_IW_GRDH_1SDV_20190929T002620_20190929T002649_029228_0351FE_D742')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/workspace/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"workflow\">Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages required for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/application/notebook/libexec/') \n",
    "sys.path.append(os.getcwd())\n",
    "import ellip_snap_helpers\n",
    "import xml.etree.ElementTree as ET\n",
    "from scipy import interpolate\n",
    "from snappy import jpy\n",
    "from snappy import ProductIO\n",
    "from snappy import GPF\n",
    "from snappy import HashMap\n",
    "\n",
    "import dateutil.parser as parser\n",
    "import gc\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely.geos import ReadingError\n",
    "import gzip\n",
    "import shutil\n",
    "import csv \n",
    "import gdal\n",
    "import osr\n",
    "import math\n",
    "import time\n",
    "import exifread\n",
    "import lxml.etree as etree\n",
    "import rasterio\n",
    "\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from shapely.geometry import box\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import glob\n",
    "\n",
    "sys.path.append('/opt/anaconda/bin/')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from osgeo.gdalconst import GA_ReadOnly\n",
    "from struct import unpack\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import cioppy\n",
    "ciop = cioppy.Cioppy()\n",
    "\n",
    "os.environ['LD_LIBRARY_PATH'] = '/opt/v94/runtime/glnxa64:/opt/v94/bin/glnxa64:/opt/v94/sys/os/glnxa64:/opt/v94/extern/bin/glnxa64'\n",
    "import run_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if aoi['value'] == 'Full':\n",
    "    aoi_wkt = cascaded_union(search.geometry.values).wkt\n",
    "    min_lon, min_lat, max_lon, max_lat = cascaded_union(search.geometry.values).bounds\n",
    "\n",
    "else:\n",
    "\n",
    "    try:\n",
    "        aoi_wkt = loads(aoi['value']).wkt\n",
    "        min_lon, min_lat, max_lon, max_lat = loads(aoi['value']).bounds\n",
    "\n",
    "    except ReadingError:\n",
    "\n",
    "        aoi_wkt = box(*[float(i) for i in aoi['value'].split(',')]).wkt\n",
    "        min_lon, min_lat, max_lon, max_lat = [float(i) for i in aoi['value'].split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print aoi_wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if all the products have the same track number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_TR = [None]*len(input_references)\n",
    "\n",
    "for index,product_ref in enumerate(input_references):\n",
    "    \n",
    "    result_prod = ciop.search(end_point=product_ref,\n",
    "                              params=[],\n",
    "                              output_fields='startdate,track',\n",
    "                              model='EOP')\n",
    "    \n",
    "    product_TR[index] = result_prod[0]['track']\n",
    "    \n",
    "    if index==0:\n",
    "        \n",
    "        slave_date = result_prod[0]['startdate'][:10]\n",
    "    \n",
    "    elif result_prod[0]['startdate'][:10] > slave_date:\n",
    "    \n",
    "        slave_date = result_prod[0]['startdate'][:10]\n",
    "\n",
    "if not all(x == product_TR[0] for x in product_TR):\n",
    "\n",
    "    raise ValueError('Not all products pertain the same track!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "s1meta = \"manifest.safe\"\n",
    "\n",
    "#slave_date = ''\n",
    "\n",
    "slave_products = []\n",
    "master_products = []\n",
    "\n",
    "slave_prefix = []\n",
    "master_prefix = []\n",
    "\n",
    "dates = []\n",
    "\n",
    "for index, identifier in enumerate(input_identifiers):\n",
    "    \n",
    "    s1_zip_file = os.path.join(data_path, identifier + '.zip') \n",
    "    s1_meta_file = os.path.join(data_path, identifier, identifier + '.SAFE', 'manifest.safe')\n",
    "\n",
    "    if os.path.isfile(s1_zip_file):\n",
    "        s1prd = s1_zip_file\n",
    "    elif os.path.isfile(s1_meta_file):\n",
    "        s1prd = s1_meta_file\n",
    "\n",
    "    print identifier, s1prd\n",
    "    reader = ProductIO.getProductReader(\"SENTINEL-1\")\n",
    "    product = reader.readProductNodes(s1prd, None)\n",
    "    \n",
    "    \n",
    "    width = product.getSceneRasterWidth()\n",
    "    height = product.getSceneRasterHeight()\n",
    "    name = product.getName()\n",
    "    start_date = parser.parse(product.getStartTime().toString()).isoformat()\n",
    "    \n",
    "    dates.append(start_date[:19])\n",
    "\n",
    "    if start_date[:10] == slave_date:\n",
    "        \n",
    "            slave_products.append(s1prd)\n",
    "            print(\"\\nProduct: %s, %d x %d pixels of %s assigned as slave\" % (name, width, height, start_date))\n",
    "            slave_prefix.append(identifier.split('_')[-1]) \n",
    "            slave_data_take = identifier.split('_')[-2]\n",
    "    else:\n",
    "            master_products.append(s1prd)\n",
    "            print(\"\\nProduct: %s, %d x %d pixels of %s assigned as master\" % (name, width, height, start_date))\n",
    "            master_data_take = identifier.split('_')[-2]  \n",
    "            master_prefix.append(identifier.split('_')[-1]) \n",
    "\n",
    "                        \n",
    "output_name = 'S1_OFFSET_TRACKING_%s_%s' % (parser.parse(min(dates)).strftime('%Y%m%d%H%M%S'),\n",
    "                                                     parser.parse(max(dates)).strftime('%Y%m%d%H%M%S'))\n",
    "\n",
    "print(\"\\nco-registered OUTPUT Img name is %s\"%output_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph = ellip_snap_helpers.GraphProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and if need assemble the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Read'\n",
    "\n",
    "node_id = 'Read'\n",
    "\n",
    "source_node_id = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(slave_products) > 1:\n",
    "  \n",
    "    slave_read_nodes = []\n",
    "    \n",
    "    # Read \n",
    "    for index, slave_identifier in enumerate(slave_products):\n",
    "        \n",
    "        operator = 'Read'\n",
    "        \n",
    "        parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "        \n",
    "        node_id = 'Read-S(%s)' % index\n",
    "        \n",
    "        source_node_id = ''\n",
    "        \n",
    "        parameters['file'] = slave_identifier\n",
    "                \n",
    "        mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "    \n",
    "        slave_read_nodes.append(node_id)\n",
    "    \n",
    "    \n",
    "    source_nodes_id = slave_read_nodes\n",
    "        \n",
    "    operator = 'SliceAssembly'\n",
    "       \n",
    "    node_id = 'SliceAssembly-S'\n",
    "    \n",
    "    parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "    \n",
    "    #parameters['selectedPolarisations'] = polarisation['value']\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes_id)\n",
    "\n",
    "    source_slave_orbit = node_id\n",
    "    \n",
    "else:\n",
    "    \n",
    "    operator = 'Read'\n",
    "        \n",
    "    parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "        \n",
    "    node_id = 'Read-S'\n",
    "        \n",
    "    source_node_id = ''\n",
    "        \n",
    "    parameters['file'] = slave_products[0]\n",
    "        \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "    \n",
    "source_slave_orbit = node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(master_products) > 1:\n",
    "      \n",
    "    master_read_nodes = []\n",
    "    \n",
    "    # Read \n",
    "    for index, master_identifer in enumerate(master_products):\n",
    "        \n",
    "        operator = 'Read'\n",
    "        \n",
    "        parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "        \n",
    "        node_id = 'Read-M(%s)' % index\n",
    "        \n",
    "        source_node_id = ''\n",
    "        \n",
    "        parameters['file'] = master_identifer\n",
    "        \n",
    "        mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "    \n",
    "        master_read_nodes.append(node_id)\n",
    "    \n",
    "    \n",
    "    source_nodes_id = master_read_nodes\n",
    "        \n",
    "    operator = 'SliceAssembly'\n",
    "       \n",
    "    node_id = 'SliceAssembly-M'\n",
    "    \n",
    "    parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "    \n",
    "    #parameters['selectedPolarisations'] = polarisation['value']\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes_id)\n",
    "\n",
    "    source_master_orbit = node_id\n",
    "    \n",
    "else:\n",
    "    \n",
    "    operator = 'Read'\n",
    "        \n",
    "    parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "        \n",
    "    node_id = 'Read-M'\n",
    "        \n",
    "    source_node_id = ''\n",
    "        \n",
    "    parameters['file'] = master_products[0]\n",
    "        \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "    \n",
    "source_master_orbit = node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply orbit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Apply-Orbit-File'\n",
    "\n",
    "node_id = 'Apply-Orbit-File-S' \n",
    "\n",
    "source_node_id = source_slave_orbit\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['orbitType'] = 'Sentinel Restituted (Auto Download)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Apply-Orbit-File'\n",
    "\n",
    "node_id = 'Apply-Orbit-File-M' \n",
    "\n",
    "source_node_id = source_master_orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land/sea mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Land-Sea-Mask'\n",
    "\n",
    "node_id = 'Land-Sea-Mask-S' \n",
    "\n",
    "source_node_id = 'Apply-Orbit-File-S' \n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['landMask'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Land-Sea-Mask'\n",
    "\n",
    "node_id = 'Land-Sea-Mask-M' \n",
    "\n",
    "source_node_id = 'Apply-Orbit-File-M' \n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['landMask'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEM assisted coregistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'DEM-Assisted-Coregistration'\n",
    "\n",
    "node_id = 'DEM-Assisted-Coregistration' \n",
    "\n",
    "source_node_id = ['Land-Sea-Mask-S',\n",
    "                  'Land-Sea-Mask-M']\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Subset'\n",
    "\n",
    "node_id = 'Subset' \n",
    "\n",
    "source_node_id = 'DEM-Assisted-Coregistration'\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['geoRegion'] = aoi_wkt\n",
    "parameters['copyMetadata'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terrain correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Terrain-Correction'\n",
    "\n",
    "source_node_id = 'Subset' \n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['demName'] = dem['value']\n",
    "parameters['pixelSpacingInMeter'] = resolution['value']\n",
    "parameters['mapProjection'] = utm_zone['value']\n",
    "\n",
    "node_id = 'Terrain-Correction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Write'\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "parameters['file'] = output_name\n",
    "parameters['formatName'] = 'GeoTIFF-BigTIFF'\n",
    "\n",
    "node_id = 'Write'\n",
    "\n",
    "source_node_id = 'Terrain-Correction'\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate tiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tif = '{}.tif'.format(output_name)\n",
    "f = open(output_tif, 'rb')\n",
    "tags = exifread.process_file(f)\n",
    "xml_data = tags['Image OwnerName'].values\n",
    "tree = ET.XML(xml_data)\n",
    "\n",
    "metadata = dict()\n",
    "\n",
    "for child in tree.find('Image_Interpretation'):\n",
    "    band_index = child.find('BAND_INDEX').text\n",
    "    name = child.find('BAND_NAME').text\n",
    "    metadata[band_index] = name\n",
    "    \n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print gdal.Info(\"./S1_OFFSET_TRACKING_20190824002619_20190929002620.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = gdal.Open(\"./S1_OFFSET_TRACKING_20190824002619_20190929002620.tif\")\n",
    "\n",
    "geo_transform = src.GetGeoTransform()\n",
    "projection = src.GetProjection()\n",
    "\n",
    "for band_number in range(1, src.RasterCount+1):\n",
    "     \n",
    "    band_data = src.GetRasterBand(band_number).ReadAsArray()\n",
    "    band_description = metadata[str(band_number-1)]\n",
    "    \n",
    "    band_data = np.where(band_data==0, np.nan, band_data)\n",
    "    \n",
    "    print band_description\n",
    "\n",
    "    imgplot = plt.imshow(band_data)\n",
    "    plt.show()\n",
    "    \n",
    "    drv = gdal.GetDriverByName('GTiff')\n",
    "    ds = drv.Create('{}.tif'.format(band_description), band_data.shape[1], band_data.shape[0], 1, gdal.GDT_Float32)\n",
    "    ds.SetGeoTransform(geo_transform)\n",
    "    ds.SetProjection(projection)\n",
    "    ds.GetRasterBand(1).WriteArray(band_data)\n",
    "    ds.FlushCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of geotiffs produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_list = list()\n",
    "slave_list = list()\n",
    "\n",
    "for element in metadata.values():\n",
    "    if 'mst' in element:\n",
    "        master_list.append(element)\n",
    "    if 'slv' in element:\n",
    "        slave_list.append(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### writing the input_dic.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = list()\n",
    "\n",
    "for idx, master_tif in enumerate(sorted(slave_list)):\n",
    "    \n",
    "    input_list.append('input_dic_{}.txt'.format(idx))\n",
    "\n",
    "    with open('input_dic_{}.txt'.format(idx), 'wb') as file:\n",
    "        file.write('{}.tif\\n'.format(master_tif))\n",
    "        file.write('{}.tif\\n'.format(sorted(master_list)[idx]))\n",
    "        file.write('{} {} {}\\n'.format(window_size['value'],oversampling_factor['value'], pixel_size['value']))\n",
    "        file.write('{} {}\\n'.format(color_scale_limits['value'].split(',')[0], color_scale_limits['value'].split(',')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### running the package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LD_LIBRARY_PATH'] = '/opt/v94/runtime/glnxa64:/opt/v94/bin/glnxa64:/opt/v94/sys/os/glnxa64:/opt/v94/extern/bin/glnxa64'\n",
    "\n",
    "for input_file in input_list:\n",
    "    \n",
    "    print input_file\n",
    "    \n",
    "    command = 'import run_dic; mr = run_dic.initialize(); mr.run_dic(\\\"{}\\\", nargout=0)'.format(input_file)\n",
    "\n",
    "    options = ['python', '-c', command]\n",
    "    \n",
    "    p = subprocess.Popen(options,\n",
    "                         stdout=subprocess.PIPE,\n",
    "                         stdin=subprocess.PIPE,\n",
    "                         stderr=subprocess.PIPE)\n",
    "\n",
    "    res, err = p.communicate()\n",
    "\n",
    "    if res:\n",
    "        print 'RESULTS:\\n'\n",
    "        for el in res.split('\\n'):\n",
    "            print el\n",
    "\n",
    "    if err:\n",
    "        print 'ERRORS:\\n'\n",
    "        for el in res.split('\\n'):\n",
    "            print el\n",
    "\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(output_tif)\n",
    "\n",
    "for tif in master_list:\n",
    "    os.remove('{}.tif'.format(tif))\n",
    "    \n",
    "for tif in slave_list:\n",
    "    os.remove('{}.tif'.format(tif))\n",
    "    \n",
    "for input_file in input_list:\n",
    "    os.remove(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print gdal.Info('./VV_VV_2d_offset_bg.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('./'):\n",
    "    if '.tif' in file:\n",
    "        print file\n",
    "        with rasterio.open(file, 'r') as ds:\n",
    "            arr = ds.read()\n",
    "            \n",
    "        drv = gdal.GetDriverByName('GTiff')\n",
    "        ds = drv.Create('{}.tif'.format(os.path.splitext(os.path.basename(file))[0]), arr.shape[2], arr.shape[1], arr.shape[0], gdal.GDT_Byte)\n",
    "        ds.SetGeoTransform(geo_transform)\n",
    "        ds.SetProjection(projection)\n",
    "        for band_number in range(arr.shape[0]):\n",
    "            ds.GetRasterBand(band_number+1).WriteArray(arr[band_number])\n",
    "        ds.FlushCache()\n",
    "        \n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print gdal.Info('./VV_VV_2d_offset_bg.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
